{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# TyBox incremental learning with CNAS baseline model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This Notebook shows the use of PyBox (www.github.com/pavmassimo/PyBox) for the generation of a quantized incremental solution able to address an incremental class learning scenario.\n",
    "\n",
    "The CIFAR-10 dataset was used to prove the capabilities of the toolbox. Two classes in the dataset have been omitted from the initial training to simulate an incremental use case.\n",
    "\n",
    "A full description of the experiment is provided in the paper TyBox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:25.600329200Z",
     "start_time": "2023-08-26T01:01:23.990723900Z"
    },
    "id": "DIWdKfT3u2oW",
    "outputId": "57221bbc-9b53-4830-eed9-23957645d165",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pavmassimo/TyBox/tree/feature-extractor-quantization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:25.610354500Z",
     "start_time": "2023-08-26T01:01:23.999701100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:25.610354500Z",
     "start_time": "2023-08-26T01:01:24.033610Z"
    },
    "id": "8LXsQZBdvxhD",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "# from keras.utils import np_utils\n",
    "from keras import backend as K \n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('.//TyBox')\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "from TyBox import TyBox\n",
    "from TyBox import profiler\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK1IDvFOwTyf"
   },
   "source": [
    "Download and preparation of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:26.044248200Z",
     "start_time": "2023-08-26T01:01:24.041588700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "# Load data \n",
    "(train_examples, train_labels), (test_examples, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:31.989793400Z",
     "start_time": "2023-08-26T01:01:26.047244300Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_examples = train_examples.astype('float32')\n",
    "test_examples = test_examples.astype('float32')\n",
    "\n",
    "train_examples = train_examples / 255.0\n",
    "test_examples = test_examples / 255.0\n",
    "\n",
    "# # One hot encode target values\n",
    "# train_labels = np_utils.to_categorical(train_labels)\n",
    "# test_labels = np_utils.to_categorical(test_labels)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    #   rotation_range=20,\n",
    "      width_shift_range=0.1,\n",
    "      height_shift_range=0.1,\n",
    "    #   shear_range=0.2,\n",
    "    #   zoom_range=0.2,\n",
    "      horizontal_flip=True\n",
    "    #   fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# train_datagen.fit(train_examples)\n",
    "\n",
    "# # Flow training images in batches of 96 using train_datagen generator\n",
    "# train_generator = train_datagen.flow(train_examples, test_dataset, batch_size=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcyR4LVQwu-r"
   },
   "source": [
    "### Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:47.289575800Z",
     "start_time": "2023-08-26T01:01:47.230339300Z"
    },
    "id": "RVgjvvz9kGj_",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('input_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:47.750334900Z",
     "start_time": "2023-08-26T01:01:47.294555100Z"
    },
    "id": "e_tRYC64udqj",
    "outputId": "584aa7e9-9813-4402-f59f-e2b79b047ca7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bETUJ97waT84"
   },
   "source": [
    "### Model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "f2474483",
    "papermill": {
     "duration": 0.032468,
     "end_time": "2023-03-20T10:48:45.351083",
     "exception": false,
     "start_time": "2023-03-20T10:48:45.318615",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "lrate = 0.00125\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=lrate)\n",
    "\n",
    "model.compile(loss=keras.losses.CategoricalCrossentropy(), optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:48.265398700Z",
     "start_time": "2023-08-26T01:01:48.009208500Z"
    },
    "id": "tTPTMHR3T3wB",
    "outputId": "7215848d-8809-4eb9-baf3-70dbd0f99ebb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "layer_w = model.layers[-1].get_weights()[0]\n",
    "weights = []\n",
    "\n",
    "for elem in layer_w:\n",
    "  weights.append(elem[8:10])\n",
    "\n",
    "biases = np.array(model.layers[-1].get_weights()[1])\n",
    "\n",
    "weights = np.array(weights)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RP2-yF3_wxMU"
   },
   "source": [
    "## Network Profiler\n",
    "It is possible now to initialize the profiler with the defined model.\n",
    "The profiler can provide useful information to the designer of the network on the memory occupations in terms of weights and activations, in total and at a per-layer granularity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:48.362698Z",
     "start_time": "2023-08-26T01:01:48.268389600Z"
    },
    "id": "vJvn1ufBwqiS",
    "outputId": "9da475a1-545b-4aaa-db24-681630646378",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# profiler = profiler.Profiler(\"model\", model)\n",
    "profiler = profiler.Profiler(network_name=\"model\", model=model, precisions=[[32, 32], [32, 32]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:48.363698300Z",
     "start_time": "2023-08-26T01:01:48.350734200Z"
    },
    "id": "Z8Alhz9Dw30T",
    "outputId": "e5c33458-385b-43ef-f5b8-8d0412f4ae20",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "profiler.print_occupations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:48.528045600Z",
     "start_time": "2023-08-26T01:01:48.363698300Z"
    },
    "id": "epp-J7_Rw6kS",
    "outputId": "976dd1cd-2360-4d49-cdd0-66fe4675b156",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "profiler.print_per_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNIkiHyjxA_h"
   },
   "source": [
    "## Train the base network\n",
    "\n",
    "We use the complete train dataset to train the base neural network on the task of recognizing the first 7 digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:48.651696200Z",
     "start_time": "2023-08-26T01:01:48.393407800Z"
    },
    "id": "_pO-kXKdw9x6",
    "outputId": "65e3bbfc-7325-4365-fc2d-e934d019d14e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "categorical_cifar_labels = np.zeros((50000, 10))\n",
    "for i in range(len(train_labels)):\n",
    "    categorical_cifar_labels[i][train_labels[i]] = 1\n",
    "\n",
    "train_labels = categorical_cifar_labels\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:48.698725200Z",
     "start_time": "2023-08-26T01:01:48.563952Z"
    },
    "id": "XotQlepH0hsO",
    "outputId": "f6556a35-fa06-44be-f45c-d8f3e9055d2a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "categorical_test_labels = np.zeros(shape=(10000, 10))\n",
    "for i in range(len(test_labels)):\n",
    "    categorical_test_labels[i][test_labels[i]] = 1\n",
    "\n",
    "test_labels = categorical_test_labels\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:49.867145200Z",
     "start_time": "2023-08-26T01:01:48.625786800Z"
    },
    "id": "0NuXqg_L0jF9",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "incremental_examples = np.empty((10000, 32, 32, 3))\n",
    "start_examples = np.empty((10000, 32, 32, 3))\n",
    "incremental_labels = np.empty((10000,10), dtype=np.uint8)\n",
    "start_labels = np.empty((10000,10), dtype=np.uint8)\n",
    "index_incremental = 0\n",
    "index_start = 0\n",
    "\n",
    "# Ship (8) and truck (9) are temporarily excluded by the dataset\n",
    "for i in range(len(train_examples)):\n",
    "    if np.argmax(train_labels[i]) > 7:\n",
    "        if index_incremental >= 10000:\n",
    "            continue\n",
    "        incremental_examples[index_incremental] = train_examples[i]\n",
    "        incremental_labels[index_incremental] = train_labels[i]\n",
    "        index_incremental += 1\n",
    "    else:\n",
    "        if index_start >= 10000:\n",
    "            continue\n",
    "        start_examples[index_start] = train_examples[i]\n",
    "        start_labels[index_start] = train_labels[i]\n",
    "        index_start += 1\n",
    "        \n",
    "incremental_examples_test = np.empty((2000, 32, 32, 3))\n",
    "start_examples_test = np.empty((2000, 32, 32, 3))\n",
    "incremental_labels_test = np.empty((2000,10), dtype=np.uint8)\n",
    "start_labels_test = np.empty((2000,10), dtype=np.uint8)\n",
    "index_incremental = 0\n",
    "index_start = 0\n",
    "\n",
    "for i in range(len(test_examples)):\n",
    "    if np.argmax(test_labels[i]) > 7:\n",
    "        if index_incremental >= 2000:\n",
    "            continue\n",
    "        incremental_examples_test[index_incremental] = test_examples[i]\n",
    "        incremental_labels_test[index_incremental] = test_labels[i]\n",
    "        index_incremental += 1\n",
    "    else:\n",
    "        if index_start >= 2000:\n",
    "            continue\n",
    "        start_examples_test[index_start] = test_examples[i]\n",
    "        start_labels_test[index_start] = test_labels[i]\n",
    "        index_start += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:50.155850600Z",
     "start_time": "2023-08-26T01:01:49.908519400Z"
    },
    "id": "MM3IPv8oYP2q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "layer_2 = model.layers[-1].get_weights()\n",
    "layer_2_w = layer_2[0]\n",
    "\n",
    "for i in range(len(layer_2_w)):\n",
    "  layer_2_w[i][8] = weights[i][0]\n",
    "  layer_2_w[i][9] = weights[i][1]\n",
    "\n",
    "layer_2[0] = layer_2_w\n",
    "\n",
    "layer_2[1][8] = biases[0]\n",
    "layer_2[1][9] = biases[1]\n",
    "\n",
    "model.layers[-1].set_weights(layer_2)\n",
    "print(model.layers[-1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:53.123939100Z",
     "start_time": "2023-08-26T01:01:50.244612700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#load the model weights\n",
    "# model.load_weights('/kaggle/input/bestcheckpoint/model_trained')\n",
    "model.load_weights('D:\\Download\\IncLearn_resultReplication_modelWeights\\model_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:01:53.352531600Z",
     "start_time": "2023-08-26T01:01:53.128924200Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(model.layers[-1].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:03:02.246460Z",
     "start_time": "2023-08-26T01:01:53.357517200Z"
    },
    "id": "PQP_y4-C0smN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model.load_weights('model_trained')\n",
    "start_examples_scores = model.evaluate(start_examples_test, start_labels_test)\n",
    "incremental_examples_scores = model.evaluate(incremental_examples_test, incremental_labels_test)\n",
    "test_scores = model.evaluate(test_examples, test_labels)\n",
    "print(start_examples_scores, incremental_examples_scores, test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uD_E3gB312Fp"
   },
   "source": [
    "## Python Incremental solution\n",
    "\n",
    "To generate the python version of the incremental solution, it's sufficient to call \n",
    "\n",
    "*Tybox.create_python_learning_solution(tf_model, mem_available, precision)*\n",
    "\n",
    "where mem_available is the amount of memory that can be dedicated to the machine learning on device (in Bytes), and precision is data precision of model and activations in bit (currently TyBox support only 32-bit floating point precision).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:03:44.793818900Z",
     "start_time": "2023-08-26T01:03:02.220530100Z"
    },
    "id": "SsRUev6L10uN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Mf_lite, Mc_python = TyBox.create_python_learning_solution(model, 9479965, 32)\n",
    "\n",
    "# # Create a compressible model for TFLite using integer-only quantization\n",
    "# def representative_data_gen():\n",
    "#     for input_value in tf.data.Dataset.from_tensor_slices(train_examples).batch(1).take(500):\n",
    "#         yield [input_value]\n",
    "# yield_representative_dataset = representative_data_gen\n",
    "# Mf_lite, Mc_python = TyBox.create_python_learning_solution(model, 2416132, 8, yield_representative_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:04:25.772676300Z",
     "start_time": "2023-08-26T01:03:44.902570900Z"
    },
    "id": "aFNkr2YM2Lod",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"mf.tflite\", \"wb\") as file:\n",
    "    file.write(Mf_lite)\n",
    "\n",
    "#tf-lite model preparation\n",
    "interpreter = tf.lite.Interpreter('mf.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "print(input_details)\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(output_details)\n",
    "\n",
    "#feature extraction with the tf-lite model\n",
    "extracted_features = []\n",
    "for i in range(len(train_labels)):\n",
    "    input_data = train_examples[i].reshape((1, 32, 32, 3))\n",
    "    \n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    \n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    # print(output)\n",
    "\n",
    "    extracted_features.append(interpreter.get_tensor(output_details['index']))\n",
    "extracted_features = np.array(extracted_features)[:,0,:]\n",
    "# print(test_feature.shape, test_feature.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:04:33.971593200Z",
     "start_time": "2023-08-26T01:04:25.803594600Z"
    },
    "id": "Nu9TdRYN2QP0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_features_test = []\n",
    "for i in range(len(test_labels)):\n",
    "    input_data = test_examples[i].reshape((1, 32, 32, 3))\n",
    "    \n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    \n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    # print(output)\n",
    "\n",
    "    extracted_features_test.append(interpreter.get_tensor(output_details['index']))\n",
    "extracted_features_test = np.array(extracted_features_test)[:,0,:]\n",
    "# print(test_feature.shape, test_feature.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:04:36.952074900Z",
     "start_time": "2023-08-26T01:04:33.975582Z"
    },
    "id": "b7W8Dl8v2h1b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_start_features_test = []\n",
    "for i in range(len(start_labels_test)):\n",
    "    input_data = start_examples_test[i].reshape((1, 32, 32, 3))\n",
    "    \n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    \n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    # print(output)\n",
    "\n",
    "    extracted_start_features_test.append(interpreter.get_tensor(output_details['index']))\n",
    "extracted_start_features_test = np.array(extracted_start_features_test)[:,0,:]\n",
    "# print(test_feature.shape, test_feature.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:04:45.375813500Z",
     "start_time": "2023-08-26T01:04:37.172411700Z"
    },
    "id": "o7Eg6M6r2l9r",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_start_features = []\n",
    "for i in range(len(start_labels)):\n",
    "    input_data = start_examples[i].reshape((1, 32, 32, 3))\n",
    "    \n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    \n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    # print(output)\n",
    "\n",
    "    extracted_start_features.append(interpreter.get_tensor(output_details['index']))\n",
    "extracted_start_features = np.array(extracted_start_features)[:,0,:]\n",
    "# print(test_feature.shape, test_feature.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:04:57.711890700Z",
     "start_time": "2023-08-26T01:04:45.382796800Z"
    },
    "id": "UWUFlJyC2oon",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_incremental_features = []\n",
    "for i in range(len(incremental_labels)):\n",
    "    input_data = incremental_examples[i].reshape((1, 32, 32, 3))\n",
    "    \n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    \n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    # print(output)\n",
    "\n",
    "    extracted_incremental_features.append(interpreter.get_tensor(output_details['index']))\n",
    "extracted_incremental_features = np.array(extracted_incremental_features)[:,0,:]\n",
    "# print(test_feature.shape, test_feature.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T01:04:59.358562700Z",
     "start_time": "2023-08-26T01:04:57.712890800Z"
    },
    "id": "za6ml0Lo2sZr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_incremental_features_test = []\n",
    "for i in range(len(incremental_labels_test)):\n",
    "    input_data = incremental_examples_test[i].reshape((1, 32, 32, 3))\n",
    "    \n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    \n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "    # print(output)\n",
    "\n",
    "    extracted_incremental_features_test.append(interpreter.get_tensor(output_details['index']))\n",
    "extracted_incremental_features_test = np.array(extracted_incremental_features_test)[:,0,:]\n",
    "# print(test_feature.shape, test_feature.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFDWipCW3PEg"
   },
   "source": [
    "### TyBox: python model usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T06:23:27.056236400Z",
     "start_time": "2023-08-26T01:04:59.435600900Z"
    },
    "id": "3CIs2tP32t9L",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#n of times the experiment will be repeated.\n",
    "n_repetitions = 5\n",
    "\n",
    "#n of data used in the experiment\n",
    "exp_l = 700\n",
    "\n",
    "#time of the introduction of the new classes\n",
    "new_subject_time = 50\n",
    "\n",
    "accuracies_tb = []\n",
    "\n",
    "for repetition in range(n_repetitions):\n",
    "    res_acc_old_tb = []\n",
    "    res_acc_new_tb = []\n",
    "\n",
    "    #load the original model and convert it\n",
    "#     model.load_weights('model_trained')\n",
    "    fe_model, python_model = TyBox.create_python_learning_solution(model, 9479965, 32)\n",
    "#     def representative_data_gen():\n",
    "#         for input_value in tf.data.Dataset.from_tensor_slices(train_examples).batch(1).take(500):\n",
    "#             yield [input_value]\n",
    "#     yield_representative_dataset = representative_data_gen\n",
    "#     fe_model, python_model = TyBox.create_python_learning_solution(model, 2416132, 8, yield_representative_dataset)\n",
    "    python_model.set_lr(0.00025)\n",
    "\n",
    "    #fix seed for reproducibility\n",
    "    random.seed(395 + repetition*52)\n",
    "\n",
    "    indices = random.sample(range(len(extracted_features)), exp_l)\n",
    "    indices_2 = random.sample(range(len(extracted_start_features)), exp_l)\n",
    "    \n",
    "    step = 0\n",
    "\n",
    "    for i in indices:\n",
    "\n",
    "        if step < new_subject_time:\n",
    "            sample = indices_2[step]\n",
    "            sample_data = extracted_start_features[sample]\n",
    "            sample_label = start_labels[sample]\n",
    "        \n",
    "        else:\n",
    "            sample = i\n",
    "            sample_data = extracted_features[sample]\n",
    "            sample_label = train_labels[sample]\n",
    "        \n",
    "        #push datum into buffer and train on the whole buffer\n",
    "        python_model.push_and_train(sample_data, sample_label)\n",
    "\n",
    "        #evaluate accuracies on test sets\n",
    "\n",
    "        accuracy_old = python_model.evaluate(extracted_start_features_test[:200], start_labels_test[:200], output_details[\"quantization\"])\n",
    "        accuracy_new = python_model.evaluate(extracted_incremental_features_test[:200], incremental_labels_test[:200], output_details[\"quantization\"])\n",
    "        \n",
    "        res_acc_old_tb.append(accuracy_old)\n",
    "        res_acc_new_tb.append(accuracy_new)\n",
    "\n",
    "        \n",
    "        print(step, accuracy_new, accuracy_old)\n",
    "        step += 1\n",
    "    accuracies_tb.append((res_acc_old_tb, res_acc_new_tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T06:23:27.899876600Z",
     "start_time": "2023-08-26T06:23:27.221749700Z"
    },
    "id": "8azKmXh83vaU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "avg_accuracies_old_tb = []\n",
    "for i in range(len(accuracies_tb[0][0])):\n",
    "  avg = 0\n",
    "  for ii in range(len(accuracies_tb)):\n",
    "    avg += accuracies_tb[ii][0][i]\n",
    "  avg = avg / len(accuracies_tb)\n",
    "  avg_accuracies_old_tb.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T06:23:27.956042100Z",
     "start_time": "2023-08-26T06:23:27.411598900Z"
    },
    "id": "UIyW1x0n9T9Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "std_dev_accuracies_old_tb = []\n",
    "for i in range(len(avg_accuracies_old_tb)):\n",
    "  std_dev = 0\n",
    "  for ii in range(len(accuracies_tb)):\n",
    "    std_dev += (avg_accuracies_old_tb[i] - accuracies_tb[ii][0][i]) ** 2\n",
    "  std_dev = math.sqrt(std_dev / len(accuracies_tb))\n",
    "  std_dev_accuracies_old_tb.append(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T06:23:27.963942600Z",
     "start_time": "2023-08-26T06:23:27.509599800Z"
    },
    "id": "-CwIPsJM9nxN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "avg_accuracies_new_tb = []\n",
    "for i in range(len(accuracies_tb[0][1])):\n",
    "  avg = 0\n",
    "  for ii in range(len(accuracies_tb)):\n",
    "    avg += accuracies_tb[ii][1][i]\n",
    "  avg = avg / len(accuracies_tb)\n",
    "  avg_accuracies_new_tb.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T06:23:27.963942600Z",
     "start_time": "2023-08-26T06:23:27.565885100Z"
    },
    "id": "-AZGkVEG90a0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "std_dev_accuracies_new_tb = []\n",
    "for i in range(len(avg_accuracies_new_tb)):\n",
    "  std_dev = 0\n",
    "  for ii in range(len(accuracies_tb)):\n",
    "    std_dev += (avg_accuracies_new_tb[i] - accuracies_tb[ii][1][i]) ** 2\n",
    "  std_dev = math.sqrt(std_dev / len(accuracies_tb))\n",
    "  std_dev_accuracies_new_tb.append(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-26T06:23:29.838800700Z",
     "start_time": "2023-08-26T06:23:27.784905300Z"
    },
    "id": "HVYkyljK9_lM",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.plot(avg_accuracies_old_tb, label=\"toolbox 0-7\")\n",
    "std_low = [avg_accuracies_old_tb[i] - 2*std_dev_accuracies_old_tb[i] for i in range(len(avg_accuracies_old_tb))]\n",
    "std_high = [min(avg_accuracies_old_tb[i] + 2*std_dev_accuracies_old_tb[i], 1) for i in range(len(avg_accuracies_old_tb))]\n",
    "plt.fill_between([i for i in range(exp_l)], std_low, std_high, alpha=0.5)\n",
    "\n",
    "plt.plot(avg_accuracies_new_tb, label=\"toolbox 8-9\")\n",
    "std_low = [max(avg_accuracies_new_tb[i] - 2*std_dev_accuracies_new_tb[i], 0) for i in range(len(avg_accuracies_new_tb))]\n",
    "std_high = [min(avg_accuracies_new_tb[i] + 2*std_dev_accuracies_new_tb[i], 1) for i in range(len(avg_accuracies_new_tb))]\n",
    "plt.fill_between([i for i in range(exp_l)], std_low, std_high, alpha=0.5)\n",
    "\n",
    "plt.title(\"Incremental learning\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
