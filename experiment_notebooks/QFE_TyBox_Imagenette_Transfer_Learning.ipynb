{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07t0myrnHIKs",
    "outputId": "6e4fcb9e-e197-4432-9aef-ee774462a3e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/pavmassimo/TyBox/tree/feature-extractor-quantization.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA6GTxx9WQeF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.append('.//TyBox')\n",
    "\n",
    "from TyBox import TyBox\n",
    "!apt-get -qq install xxd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lCvJwuNfaynL"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yghkVfVVM30O"
   },
   "source": [
    "### Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvT1PyTZM5vl",
    "outputId": "9006816f-da13-4e68-f036-8e9940c1171e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "# Load data \n",
    "(x_train_cifar10, y_train_cifar10), (x_test_cifar10, y_test_cifar10) = cifar10.load_data()\n",
    "\n",
    "x_train_cifar10 = x_train_cifar10.astype('float32')\n",
    "x_test_cifar10 = x_test_cifar10.astype('float32')\n",
    "\n",
    "x_train_cifar10 = x_train_cifar10 / 255.0\n",
    "x_test_cifar10 = x_test_cifar10 / 255.0\n",
    "\n",
    "# # One hot encode target values\n",
    "# y_train_cifar10 = np_utils.to_categorical(y_train_cifar10)\n",
    "# y_test_cifar10 = np_utils.to_categorical(y_test_cifar10)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_cifar10, y_train_cifar10))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_cifar10, y_test_cifar10))\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek-i4ISudErD"
   },
   "source": [
    "### Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oyZEXuJdGLy",
    "outputId": "be4d315d-d8e7-42f1-decd-b301a9491cb5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from fastai.data.all import *\n",
    "\n",
    "path = untar_data(URLs.IMAGENETTE_160)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQrJ6V_18Tfw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "labels_dict = dict(\n",
    "    n01440764='0',\n",
    "    n02102040='1',\n",
    "    n02979186='2',\n",
    "    n03000684='3',\n",
    "    n03028079='4',\n",
    "    n03394916='5',\n",
    "    n03417042='6',\n",
    "    n03425413='7',\n",
    "    n03445777='8',\n",
    "    n03888257='9'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZezFVk3AdPgs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "# print(path)\n",
    "train_dir = os.path.join(path, 'train')\n",
    "# print(train_dir)\n",
    "\n",
    "def get_labels(files):\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        labels.append(parent_label(file))\n",
    "    return labels\n",
    "\n",
    "train_files = get_image_files(train_dir)\n",
    "# print(train_files)\n",
    "imagenette_labels = get_labels(train_files)\n",
    "# print(len(imagenette_labels))\n",
    "y_train_imagenette = []\n",
    "for label in imagenette_labels:\n",
    "    y_train_imagenette.append(int(labels_dict[label]))\n",
    "\n",
    "y_train_imagenette = np.array(y_train_imagenette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgUa6fq58coq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "x_train_imagenette = []\n",
    "for image in train_files:\n",
    "    # print(image)\n",
    "    im = cv2.imread(str(image))\n",
    "    resized_im = cv2.resize(im, (32, 32))\n",
    "    # print(type(im))\n",
    "    # print(resized_im.shape)\n",
    "    # print(type(im.shape))\n",
    "    x_train_imagenette.append(resized_im)\n",
    "# print(len(x_train_imagenette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAkb-h0bKcU7"
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EONFOsgm9rnx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('input_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIMBUc1K9xsH",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "pruning_lrate = 0.00135\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=pruning_lrate)\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pyIseBtKoPj"
   },
   "source": [
    "## TyBox transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bHW5CtmCpqt",
    "outputId": "a14e189f-0cad-4691-9319-16bb688b0142",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a compressible model for TFLite using integer-only quantization\n",
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train_cifar10).batch(1).take(500):\n",
    "        yield [input_value]\n",
    "yield_representative_dataset = representative_data_gen\n",
    "Mf_lite, Mc_python = TyBox.create_python_learning_solution(model, 2509645, 8, yield_representative_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8U2k8Hl8XCIS",
    "outputId": "a3960118-5551-461c-b9ad-6f9a8522e459",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with open(\"mf.tflite\", \"wb\") as file:\n",
    "    file.write(Mf_lite)\n",
    "\n",
    "#tf-lite model preparation\n",
    "interpreter = tf.lite.Interpreter('mf.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "print(input_details)\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LebC_vCX9-Pp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_features = []\n",
    "for i in range(len(y_train_cifar10)):\n",
    "    input_data = x_train_cifar10[i].astype('float32').reshape((1, 32, 32, 3))\n",
    "\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    out = interpreter.get_tensor(output_details[\"index\"])\n",
    "    extracted_features.append(out)\n",
    "extracted_features = np.array(extracted_features)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a1TYoRmYPcC",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "extracted_imagenette_features = []\n",
    "# x_train_imagenette, y_train_imagenette\n",
    "for i in range(len(y_train_imagenette)):\n",
    "    input_data = x_train_imagenette[i].astype('float32').reshape((1, 32, 32, 3))\n",
    "\n",
    "    if input_details['dtype'] == np.uint8:\n",
    "        input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "        input_data = input_data / input_scale + input_zero_point\n",
    "    input_data = input_data.astype(input_details[\"dtype\"])\n",
    "    # print(input_data)\n",
    "\n",
    "    interpreter.set_tensor(input_details[\"index\"], input_data)\n",
    "    interpreter.invoke()\n",
    "    out = interpreter.get_tensor(output_details[\"index\"])\n",
    "    extracted_imagenette_features.append(out)\n",
    "extracted_imagenette_features = np.array(extracted_imagenette_features)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7FyW3uc0emT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "categorical_cifar10_labels = np.zeros(shape=(50000,10))\n",
    "for i in range(len(y_train_cifar10)):\n",
    "    categorical_cifar10_labels[i][y_train_cifar10[i]] = 1\n",
    "\n",
    "categorical_imagenette_labels = np.zeros((9469, 10))\n",
    "for i in range(len(y_train_imagenette)):\n",
    "  categorical_imagenette_labels[i][y_train_imagenette[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PWeAiUqhDT4",
    "outputId": "95df5a8e-86b1-4f93-aee9-839e7246de9c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#n of times the experiment will be repeated.\n",
    "n_repetitions = 5\n",
    "\n",
    "#n of data used in the experiment\n",
    "exp_l = 700\n",
    "\n",
    "repetitions_tb = []\n",
    "for repetition in range(n_repetitions):\n",
    "    res_x1 = []\n",
    "    res_acc1 = []\n",
    "    res_std = []\n",
    "\n",
    "    # Create a compressible model for TFLite using integer-only quantization\n",
    "    def representative_data_gen():\n",
    "        for input_value in tf.data.Dataset.from_tensor_slices(x_train_cifar10).batch(1).take(500):\n",
    "            yield [input_value]\n",
    "    yield_representative_dataset = representative_data_gen\n",
    "    fe_model, python_model = TyBox.create_python_learning_solution(model, 2509645, 8, yield_representative_dataset)\n",
    "    python_model.set_lr(0.0015)\n",
    "\n",
    "    #sample without repetition from the training dataset\n",
    "    indices = random.sample(range(9268), exp_l)\n",
    "    \n",
    "    #fix seed for reproducibility\n",
    "    random.seed(395 + repetition*52)\n",
    "\n",
    "    step = 0\n",
    "\n",
    "    for sample in indices:\n",
    "        datum = extracted_imagenette_features[sample]\n",
    "        label = categorical_imagenette_labels[sample]\n",
    "\n",
    "        #push datum into buffer and train on the whole buffer\n",
    "        python_model.push_and_train(datum, label)\n",
    "\n",
    "        #evaluate accuracy on test set\n",
    "        accuracy = python_model.evaluate(extracted_imagenette_features[9269:], \n",
    "                                         categorical_imagenette_labels[9269:], \n",
    "                                         output_details[\"quantization\"])\n",
    "        res_acc1.append(accuracy)\n",
    "        print(step, accuracy)\n",
    "        step += 1\n",
    "    repetitions_tb.append(res_acc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzFVk5UPCB0X"
   },
   "source": [
    "save experiment results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4dj8rG1E3sS",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "avg_repetitions_tb = []\n",
    "for i in range(len(repetitions_tb[0])):\n",
    "  avg = 0\n",
    "  for ii in range(len(repetitions_tb)):\n",
    "    avg += repetitions_tb[ii][i]\n",
    "  avg = avg / len(repetitions_tb)\n",
    "  avg_repetitions_tb.append(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dpT3GV9AEie5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "std_dev_repetitions_tb = []\n",
    "for i in range(len(avg_repetitions_tb)):\n",
    "  std_dev = 0\n",
    "  for ii in range(len(repetitions_tb)):\n",
    "    std_dev += (avg_repetitions_tb[i] - repetitions_tb[ii][i]) ** 2\n",
    "  std_dev = math.sqrt(std_dev / len(repetitions_tb))\n",
    "  std_dev_repetitions_tb.append(std_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "plt.plot(avg_repetitions_tb, label=\"TyBox\")\n",
    "std_low = [avg_repetitions_tb[i] - 2*std_dev_repetitions_tb[i] for i in range(len(avg_repetitions_tb))]\n",
    "std_high = [min(avg_repetitions_tb[i] + 2*std_dev_repetitions_tb[i], 1) for i in range(len(avg_repetitions_tb))]\n",
    "plt.fill_between([i for i in range(exp_l)], std_low, std_high, alpha=0.5)\n",
    "\n",
    "# plt.plot(avg_repetitions_tf, label=\"tensorflow\")\n",
    "# std_low = [avg_repetitions_tf[i] - 2*std_dev_repetitions_tf[i] for i in range(len(avg_repetitions_tf))]\n",
    "# std_high = [min(avg_repetitions_tf[i] + 2*std_dev_repetitions_tf[i], 1) for i in range(len(avg_repetitions_tf))]\n",
    "# plt.fill_between([i for i in range(500)], std_low, std_high, alpha=0.5)\n",
    "\n",
    "plt.title(\"Transfer learning Imagenette\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=4)\n",
    "# plt.savefig('/content/drive/MyDrive/TyBox_experiments/Transfer_mnist/accuracy_192_1tf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiXBe1f5Vnmx",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# experiment = {\n",
    "#     'repetitions_tb' : repetitions_tb,\n",
    "#     'repetitions_tf' : repetitions_tf,\n",
    "#     'avg_repetitions_tf' : avg_repetitions_tf,\n",
    "#     'avg_repetitions_tb' : avg_repetitions_tb,\n",
    "#     'std_dev_repetitions_tf' : std_dev_repetitions_tf,\n",
    "#     'std_dev_repetitions_tb' : std_dev_repetitions_tb\n",
    "# }\n",
    "\n",
    "# with open('/content/drive/MyDrive/TyBox_experiments/Transfer_mnist/experiment_data_192.pickle', 'wb') as handle:\n",
    "#     pkl.dump(experiment, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
